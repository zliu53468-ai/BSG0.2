# -*- coding: utf-8 -*-
import numpy as np
import joblib
import os
import warnings
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from xgboost import XGBClassifier
from hmmlearn import hmm
import lightgbm as lgb

warnings.filterwarnings("ignore", category=UserWarning)

# =============================================================================
# å…¨åŸŸè¨­å®š
# =============================================================================
MODEL_DIR = 'models'
N_FEATURES_WINDOW = 20
LABEL_MAP = {'B': 0, 'P': 1}
REVERSE_MAP = {0: 'B', 1: 'P'}  # é æ¸¬æ™‚ä½¿ç”¨è‹±æ–‡ä»£ç¢¼ï¼Œèˆ‡å‰ç«¯ä¿æŒä¸€è‡´

# çœŸå¯¦æ­·å²æ•¸æ“š
REAL_HISTORY_DATA = [
    "P", "P", "T", "B", "T", "B", "P", "B", "P", "P", "B", "B", "T", "B", "B", "P", "B", "B", "P", "B", "B", "T", "P", "B", "B", "T", "P", "B", "P", "B", "P", "B", "B", "T", "P", "T", "B", "B", "P", "P", "B", "P", "B", "P", "T", "P", "B", "B", "B", "P", "B", "B", "B", "B", "P", "P", "P", "B", "P", "B", "P", "B", "P", "B", "T", "P", "B", "B", "P", "B", "P", "T", "B", "B", "P", "B", "B", "P", "T", "T", "B", "P", "B", "B", "P", "P", "B", "P", "B", "P", "T", "P", "B", "P", "B", "P", "T", "T", "B", "P", "B", "B", "P", "B", "B", "P", "T", "T", "B", "P", "B", "B", "B", "B", "B", "P", "P", "B", "P", "B", "B", "P", "P", "P", "P", "P", "P", "B", "B", "T", "B", "T", "B", "P", "P", "P", "B", "P", "B", "P", "B", "P", "B", "T", "P", "B", "B", "P", "B", "B", "B", "P", "P", "B", "B", "P", "B", "B", "T", "P", "T", "B", "B", "P", "B", "P", "B", "P", "B", "B", "P", "B", "P", "T", "T", "B", "B", "B", "B", "P", "B", "B", "B", "P", "B", "T", "P", "P", "B", "B", "B", "P", "P", "P", "B", "P", "B", "P", "P", "P", "B", "T", "B", "P", "B", "T", "B", "P", "B", "P", "P", "P", "P", "B", "P", "B", "P", "B", "T", "T", "B", "P", "B", "B", "P", "P", "P", "B", "P", "B", "T", "B", "P", "B", "P", "B", "T", "P", "B", "B", "P", "B", "B", "P", "T", "B", "P", "T", "B", "B", "B", "P", "T", "B", "B", "P", "B", "B", "P", "T", "B", "B", "P", "B", "P", "B", "T", "B", "B", "P", "P", "B", "B", "P", "T", "P", "P", "B", "P", "B", "B", "B", "B", "P", "B", "P", "B", "B", "T", "P", "B", "P", "B", "T", "T", "B", "P", "P", "B", "P", "P", "B", "B", "P", "B", "P", "T", "P", "P", "P", "P", "B", "B", "B", "B", "B", "P", "B", "P", "B", "P", "B", "B", "P", "B", "P", "P", "B", "B", "T", "P", "B", "P", "B", "P", "B", "B", "B", "P", "B", "P", "B", "P", "T", "B", "P", "B", "P", "T", "B", "B", "P", "B", "B", "P", "P", "P", "B", "B", "P", "B", "T", "B", "T", "B", "P", "B", "P", "T", "P", "B", "B", "P", "P", "P", "B", "P", "B", "P", "B", "B", "T", "P", "B", "P", "B", "P", "B", "B", "B", "B", "P", "B", "B", "B", "B", "B", "P", "P", "P", "P", "P", "B", "P", "P", "P", "P", "P", "B", "P", "P", "B", "P", "B", "B", "P", "T", "B", "P", "B", "P", "P", "T", "P", "B", "B", "T", "B", "P", "T", "P", "B", "P", "B", "B", "P", "B", "B", "T", "P", "P", "P", "P", "T", "P", "T", "B", "B", "P", "B", "B", "P", "P", "P", "B", "P", "B", "P", "T", "P", "P", "T", "P", "P", "B", "P", "P", "B", "P", "P", "B", "P", "P", "T", "B", "P", "B", "P", "P", "B", "B", "B", "B", "T", "T", "T", "B", "B", "B", "B", "B", "B", "P", "P", "P", "T", "P", "T", "B", "P", "P", "T", "P", "B", "P", "P", "B", "P", "P", "P", "P", "B", "P", "B", "P", "P", "B", "B", "P", "B", "B", "B", "B", "P", "P", "P", "P", "P", "T", "P", "B", "P", "P", "B", "T", "B", "B", "B", "B", "P", "B", "B", "B", "B", "B", "B", "P", "B", "P", "P", "B", "P", "P", "B", "P", "B", "B", "P", "B", "P", "P", "T", "P", "B", "P", "B", "B", "P", "P", "T", "B", "B", "P", "P", "B", "T", "T", "B", "P", "B", "B", "B", "T", "T", "B", "B", "P", "B", "T", "P", "B", "P", "B", "P", "P", "P", "B", "P", "B", "P", "P", "B", "P", "P", "P", "P", "B", "B", "P", "P", "T", "P", "B", "B", "P", "P", "B", "T", "B", "B", "P", "P", "P", "T", "P", "B", "T", "P", "B", "B", "P", "B", "B", "T", "T", "B", "B", "P", "B", "B", "P", "P", "P", "P", "B", "B", "P", "P", "T", "P", "B", "B", "P", "P", "B", "T", "B", "B", "P", "P", "P", "T", "P", "B", "T", "P", "B", "B", "P", "B", "B", "B", "B", "B", "P", "B", "T", "T", "P", "B", "B", "B", "P", "B", "B", "P", "B", "P", "B", "P", "P", "P", "P", "P", "P", "B", "B", "B", "P", "T", "P", "B", "T", "B", "B", "B", "B", "T", "B", "P", "B", "B", "B", "B", "B", "B", "P", "B", "P", "B", "B", "P", "P", "B", "P", "P", "P", "P", "B", "B", "B", "B", "B", "T", "B", "B", "P", "B", "P", "T", "P", "B", "B", "P", "B", "B", "B", "P", "P", "P", "B", "P", "P", "B", "P", "P", "B", "B", "P", "P", "B", "P", "B", "B", "B", "B", "B", "B", "B", "B", "P", "T", "P", "B", "P", "B", "P", "P", "B", "B", "P", "B", "P", "P", "T", "B", "B", "P", "P", "B", "B", "P", "B", "B", "T", "P", "P", "B", "T", "P", "B", "B", "P", "B", "P", "B", "P", "B", "B", "B", "B", "B", "P", "P", "P", "B", "B", "P", "P", "B", "T", "P", "P", "B", "T", "B", "P", "P", "P", "B", "B", "P", "B", "B", "P", "B", "P", "P", "B", "B", "B", "B", "P", "P", "T", "B", "B", "P", "P", "B", "P", "B", "P", "P", "P", "P", "B", "B", "P", "P", "B", "P", "P", "T", "P", "P", "P", "B", "B", "P", "P", "T", "P", "B", "P", "B", "B", "P", "P", "P", "B", "B", "P", "P", "B", "P", "T", "P", "P", "P", "B", "B", "P", "P", "B", "P", "B", "B", "P", "T", "B", "P", "T", "T", "P", "T", "B", "T", "P", "T", "P", "T", "P", "P", "B", "B", "P", "P", "P", "P", "P"
]

# =============================================================================
# è·¯å–®åˆ†ææ ¸å¿ƒ (BaccaratAnalyzer) - ä¿æŒä¸è®Š
# =============================================================================
class BaccaratAnalyzer:
    def __init__(self, roadmap):
        self.roadmap = [r for r in roadmap if r in ['B', 'P']]
        self.big_road_grid = self._generate_big_road_grid()

    def _generate_big_road_grid(self):
        grid = []
        if not self.roadmap: return grid
        current_col, last_result = [], None
        for result in self.roadmap:
            if result != last_result and last_result is not None:
                grid.append(current_col)
                current_col = []
            current_col.append(result)
            last_result = result
        if current_col: grid.append(current_col)
        return grid

    def _get_col_len(self, c):
        return len(self.big_road_grid[c]) if 0 <= c < len(self.big_road_grid) else 0

    def _get_derived_bead_color(self, c, r, offset):
        if c < offset: return None
        if r == 0:
            return 'R' if self._get_col_len(c - 1) == self._get_col_len(c - offset -1) else 'B'
        ref_bead_exists = r < self._get_col_len(c - offset)
        ref_bead_above_exists = (r - 1) < self._get_col_len(c - offset)
        if ref_bead_exists: return 'R'
        elif ref_bead_above_exists: return 'B'
        return 'B'

    def get_derived_roads_data(self):
        roads = {'big_eye': [], 'small': [], 'cockroach': []}
        offsets = {'big_eye': 1, 'small': 2, 'cockroach': 3}
        for name, offset in offsets.items():
            derived_road_flat = []
            if len(self.big_road_grid) < offset + 1: continue
            for c in range(offset, len(self.big_road_grid)):
                start_row = 1 if len(self.big_road_grid[c - 1]) == 1 else 0
                for r in range(start_row, 6):
                    if r >= self._get_col_len(c): break
                    color = self._get_derived_bead_color(c, r, offset)
                    if color: derived_road_flat.append(color)
            if derived_road_flat:
                grid, current_col, last_bead = [], [], None
                for bead in derived_road_flat:
                    if bead != last_bead and last_bead is not None:
                        grid.append(current_col)
                        current_col = []
                    current_col.append(bead)
                    last_bead = bead
                if current_col: grid.append(current_col)
                roads[name] = grid
        return roads

    def get_derived_road_features(self):
        roads_data = self.get_derived_roads_data()
        features = []
        for name in ['big_eye', 'small', 'cockroach']:
            road = roads_data.get(name, [])
            flat_road = [bead for col in road for bead in col] if road else []
            if len(flat_road) > 5:
                window = flat_road[-10:]
                red_count = window.count('R')
                features.append(red_count / len(window))
            else:
                features.append(0.5)
        return features

# =============================================================================
# ç‰¹å¾µå·¥ç¨‹èˆ‡è¨“ç·´ - é‡é»ä¿®æ”¹éƒ¨åˆ†
# =============================================================================
def extract_features(full_roadmap):
    features_list, labels = [], []
    
    # ç¢ºä¿æœ‰è¶³å¤ çš„æ•¸æ“šé»ä¾†å‰µå»ºç‰¹å¾µå’Œæ¨™ç±¤
    if len(full_roadmap) <= N_FEATURES_WINDOW:
        return np.array([]), np.array([])
    
    # å¾ N_FEATURES_WINDOW é–‹å§‹ï¼Œå› ç‚ºæˆ‘å€‘éœ€è¦è‡³å°‘Nå€‹æ•¸æ“šé»ä¾†æ§‹å»ºç‰¹å¾µ
    for i in range(N_FEATURES_WINDOW, len(full_roadmap)):
        # é—œéµä¿®æ”¹ï¼šåªä½¿ç”¨æ­·å²æ•¸æ“šä¾†æ§‹å»ºç‰¹å¾µ (0åˆ°i-1)
        historical_roadmap = full_roadmap[:i]
        # æ¨™ç±¤æ˜¯ç•¶å‰æ•¸æ“šé» (i)
        label = full_roadmap[i]
        
        if label not in LABEL_MAP:
            continue
            
        # å¾æ­·å²æ•¸æ“šä¸­æå–æœ€å¾ŒNå€‹çµæœä½œç‚ºçª—å£
        window = historical_roadmap[-N_FEATURES_WINDOW:]
        
        # è¨ˆç®—åŸºæœ¬ç‰¹å¾µ
        b_count = window.count('B')
        p_count = window.count('P')
        total = b_count + p_count
        
        b_ratio = b_count / total if total > 0 else 0.5
        p_ratio = p_count / total if total > 0 else 0.5
        
        # è¨ˆç®—é€£çºŒå‡ºç¾æ¬¡æ•¸
        streak = 0
        last_result = None
        for item in reversed(window):
            if item in ['B', 'P']:
                if last_result is None:
                    last_result = item
                    streak = 1
                elif item == last_result:
                    streak += 1
                else:
                    break
                    
        streak_type = LABEL_MAP.get(last_result, -1)
        prev_result = LABEL_MAP.get(window[-1], -1) if window else -1
        
        basic_features = [b_ratio, p_ratio, streak, streak_type, prev_result]
        
        # ä½¿ç”¨æ­·å²æ•¸æ“šå‰µå»ºåˆ†æå™¨
        analyzer = BaccaratAnalyzer(historical_roadmap)
        derived_features = analyzer.get_derived_road_features()
        
        # åˆä½µæ‰€æœ‰ç‰¹å¾µ
        all_features = basic_features + derived_features
        features_list.append(all_features)
        labels.append(LABEL_MAP[label])
        
    return np.array(features_list), np.array(labels)

def train():
    print("="*50)
    print("é–‹å§‹é‡æ–°è¨“ç·´ AI æ¨¡å‹ (ä½¿ç”¨æ­£ç¢ºçš„æ™‚é–“åºåˆ—æ–¹æ³•)...")
    print("="*50)
    
    if not os.path.exists(MODEL_DIR):
        os.makedirs(MODEL_DIR)
        print(f"âœ… å·²å»ºç«‹ç›®éŒ„: {MODEL_DIR}")
    
    # åªä½¿ç”¨çœŸå¯¦æ•¸æ“šï¼Œä¸å†ç”Ÿæˆåˆæˆæ•¸æ“š
    roadmap = [r for r in REAL_HISTORY_DATA if r in ['B', 'P']]
    print(f"âœ… ä½¿ç”¨ {len(roadmap)} ç­†çœŸå¯¦æ­·å²æ•¸æ“šé€²è¡Œè¨“ç·´")
    
    # è½‰æ›ç‚ºæ•¸å€¼æ ¼å¼ä¾›HMMä½¿ç”¨
    roadmap_numeric = np.array([LABEL_MAP[r] for r in roadmap]).reshape(-1, 1)
    
    # --- 1. è¨“ç·´ HMM å°ˆå®¶ ---
    print("\n--- [é–‹å§‹è¨“ç·´ HMM å°ˆå®¶] ---")
    try:
        hmm_model = hmm.CategoricalHMM(
            n_components=2, 
            n_iter=200, 
            random_state=42, 
            tol=1e-3, 
            init_params="ste"
        )
        hmm_model.fit(roadmap_numeric)
        joblib.dump(hmm_model, os.path.join(MODEL_DIR, 'hmm_model.pkl'))
        print("âœ… HMM å°ˆå®¶ (hmm_model.pkl) å·²å„²å­˜ã€‚")
    except Exception as e:
        print(f"âŒ HMM è¨“ç·´å¤±æ•—: {e}")
        return
    
    # --- 2. è¨“ç·´ XGBoost & LightGBM å°ˆå®¶ ---
    print("\n--- [é–‹å§‹è¨“ç·´ XGBoost & LightGBM å°ˆå®¶] ---")
    
    # æå–ç‰¹å¾µå’Œæ¨™ç±¤
    X, y = extract_features(roadmap)
    if len(X) == 0:
        print("âŒ ç‰¹å¾µæå–å¤±æ•— - æ•¸æ“šä¸è¶³")
        return
        
    print(f"âœ… æˆåŠŸæå– {X.shape[0]} å€‹æ¨£æœ¬ï¼Œæ¯å€‹æ¨£æœ¬æœ‰ {X.shape[1]} å€‹ç‰¹å¾µ")
    
    # ä½¿ç”¨æ™‚é–“åºåˆ—äº¤å‰é©—è­‰è©•ä¼°æ¨¡å‹
    tscv = TimeSeriesSplit(n_splits=5)
    xgb_scores, lgbm_scores = [], []
    
    # å‰µå»ºæ¨™æº–åŒ–å™¨ä¸¦æ“¬åˆå…¨éƒ¨æ•¸æ“š
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    joblib.dump(scaler, os.path.join(MODEL_DIR, 'scaler.pkl'))
    print("âœ… æ¨™æº–åŒ–å™¨ (scaler.pkl) å·²å„²å­˜ã€‚")
    
    print("\né€²è¡Œæ™‚é–“åºåˆ—äº¤å‰é©—è­‰...")
    for fold, (train_index, test_index) in enumerate(tscv.split(X_scaled)):
        X_train, X_test = X_scaled[train_index], X_scaled[test_index]
        y_train, y_test = y[train_index], y[test_index]
        
        # è¨“ç·´XGBoost
        xgb_model = XGBClassifier(
            objective='binary:logistic', 
            eval_metric='logloss', 
            n_estimators=100, 
            learning_rate=0.05, 
            max_depth=3,  # æ¸›å°‘æ·±åº¦é˜²æ­¢éæ“¬åˆ
            use_label_encoder=False, 
            random_state=42
        )
        xgb_model.fit(X_train, y_train)
        xgb_score = xgb_model.score(X_test, y_test)
        xgb_scores.append(xgb_score)
        
        # è¨“ç·´LightGBM
        lgbm_model = lgb.LGBMClassifier(
            objective='binary', 
            metric='binary_logloss', 
            n_estimators=100, 
            learning_rate=0.05, 
            max_depth=3,  # æ¸›å°‘æ·±åº¦é˜²æ­¢éæ“¬åˆ
            random_state=42
        )
        lgbm_model.fit(X_train, y_train)
        lgbm_score = lgbm_model.score(X_test, y_test)
        lgbm_scores.append(lgbm_score)
        
        print(f"æŠ˜ç–Š {fold+1}: XGBoost={xgb_score:.4f}, LightGBM={lgbm_score:.4f}")
    
    # è¼¸å‡ºäº¤å‰é©—è­‰çµæœ
    print(f"\nğŸ“Š XGBoost å¹³å‡æº–ç¢ºç‡: {np.mean(xgb_scores):.4f} (Â±{np.std(xgb_scores):.4f})")
    print(f"ğŸ“Š LightGBM å¹³å‡æº–ç¢ºç‡: {np.mean(lgbm_scores):.4f} (Â±{np.std(lgbm_scores):.4f})")
    
    # ä½¿ç”¨å…¨éƒ¨æ•¸æ“šè¨“ç·´æœ€çµ‚æ¨¡å‹
    print("\nä½¿ç”¨å…¨éƒ¨æ•¸æ“šè¨“ç·´æœ€çµ‚æ¨¡å‹...")
    
    # XGBoost
    xgb_model = XGBClassifier(
        objective='binary:logistic', 
        eval_metric='logloss', 
        n_estimators=100, 
        learning_rate=0.05, 
        max_depth=3,
        use_label_encoder=False, 
        random_state=42
    )
    xgb_model.fit(X_scaled, y)
    joblib.dump(xgb_model, os.path.join(MODEL_DIR, 'xgb_model.pkl'))
    print("âœ… XGBoost å°ˆå®¶ (xgb_model.pkl) å·²å„²å­˜ã€‚")
    
    # LightGBM
    lgbm_model = lgb.LGBMClassifier(
        objective='binary', 
        metric='binary_logloss', 
        n_estimators=100, 
        learning_rate=0.05, 
        max_depth=3,
        random_state=42
    )
    lgbm_model.fit(X_scaled, y)
    joblib.dump(lgbm_model, os.path.join(MODEL_DIR, 'lgbm_model.pkl'))
    print("âœ… LightGBM å°ˆå®¶ (lgbm_model.pkl) å·²å„²å­˜ã€‚")
    
    # è¼¸å‡ºæœ€çµ‚æ¨¡å‹åœ¨è¨“ç·´é›†ä¸Šçš„è¡¨ç¾
    xgb_train_score = xgb_model.score(X_scaled, y)
    lgbm_train_score = lgbm_model.score(X_scaled, y)
    print(f"\nğŸ¯ æœ€çµ‚æ¨¡å‹è¨“ç·´é›†æº–ç¢ºç‡:")
    print(f"   XGBoost: {xgb_train_score:.4f}")
    print(f"   LightGBM: {lgbm_train_score:.4f}")
    
    # è¼¸å‡ºåˆ†é¡å ±å‘Š
    y_pred_xgb = xgb_model.predict(X_scaled)
    y_pred_lgbm = lgbm_model.predict(X_scaled)
    
    print("\nğŸ“‹ XGBoost åˆ†é¡å ±å‘Š:")
    print(classification_report(y, y_pred_xgb, target_names=['èŠ(B)', 'é–’(P)']))
    
    print("ğŸ“‹ LightGBM åˆ†é¡å ±å‘Š:")
    print(classification_report(y, y_pred_lgbm, target_names=['èŠ(B)', 'é–’(P)']))
    
    print("\nğŸ‰ æ‰€æœ‰å°ˆå®¶æ¨¡å‹å·²æˆåŠŸè¨“ç·´ä¸¦å„²å­˜ï¼")

if __name__ == '__main__':
    train()
